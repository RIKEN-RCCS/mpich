#! /usr/bin/env perl
##
## Copyright (C) by Argonne National Laboratory
##     See COPYRIGHT in top-level directory
##

use strict;

# Create an index of web pages for MPICH
#
# Default values
# Root for the pages
my $WWWRoot=`pwd`;
chop $WWWRoot;
# Base address (installation address)
my $URLBase;
# End of line character (\r\n is DOS-friendly)
my $eol = "\r\n";
# Number of columns in table of names
my $TableCols = 3;
#
# Process arguments for any changes
foreach $a (@ARGV) {
    if ($a =~ /-?-wwwroot=(.*)/) {
	$WWWRoot = $1;
    }
    elsif ($a =~ /-?-urlbase=(.*)/) {
	$URLBase = $1;
    }
    elsif ($a =~ /-?help/) {
	print STDOUT "createhtmlindex [ -wwwroot=directory ] [ -urlbase=base ]\n\n";
	print STDOUT "Build the www index pages for MPICH.\n";
	print STDOUT "This must be run in the root of an MPICH tree; it may\n";
        print STDOUT "be run in a VPATH directory after configuring.\n";
	exit 1;
    }
    else {
	print STDERR "Unknown argument $a\n";
	exit 1;
    }
}

# Create the main index
open( OUTFD, ">$WWWRoot/www/index.html" ) ||
    die "Cannot open $WWWRoot/www/index.html\n";

&AddHeader( "Web pages for MPI" );

print OUTFD "<H2>MPI Commands</H2>$eol";
&AddDirectoryContents( "www", "www1" );

print OUTFD "<H2>MPI Routines and Constants</H2>$eol";
if (-f "www/www3/mpi.cit") {
    &createRedirects("www/www3", "mpi.cit");
}
else {
    print STDERR "Could not find mapping file\n";
}
&AddDirectoryContents( "www", "www3" );

#print OUTFD "<H2>MPE Routines</H2>$eol";
#&AddDirectoryContents( "www", "www4" );

&AddTrailer( );

close( OUTFD );

# Create the sectional indices
open( OUTFD, ">$WWWRoot/www/www1/index.htm" ) ||
    die "Cannot open $WWWRoot/www/www1/index.htm\n";

&AddHeader( "Manpages for MPICH" );
&AddDirectoryContents( "www/www1", "." );
&AddTrailer( );
close( OUTFD );

open( OUTFD, ">$WWWRoot/www/www3/index.htm" ) ||
    die "Cannot open $WWWRoot/www/www3/index.htm\n";

&AddHeader( "Web pages for MPI Routines and Constants" );
&AddDirectoryContents( "www/www3", "." );
&AddTrailer( );
close( OUTFD );

# open( OUTFD, ">$WWWRoot/www/www4/index.htm" ) ||
#     die "Cannot open $WWWRoot/www/www4/index.htm\n";

# &AddHeader( "Web pages for MPE Routines" );
# &AddDirectoryContents( "www/www4", "." );
# &AddTrailer( );
# close( OUTFD );


0;
# ---------------------------------------------------------------------------
# Support routines.
# All write to OUTFD and use $eol for end-of-line
# ---------------------------------------------------------------------------
sub AddHeader {
    my $title = $_[0];
    my ($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst) = localtime();
    my $today = sprintf("%d/%d/%d", $mon + 1, $mday, $year + 1900);
    print OUTFD "<HTML>$eol<HEAD>$eol<TITLE>$title</TITLE>$eol";
    print OUTFD "<!-- This file generated by createhtmlindex on $today -->$eol";
    print OUTFD "</HEAD>$eol<BODY BGCOLOR=\"FFFFFF\">$eol";
    print OUTFD "<H1>$title</H1>$eol";
}

sub AddTrailer {
    print OUTFD "</BODY>$eol</HTML>$eol";
}

# For the items (mostly MPI constants) that are within a single web page,
# create a redirect page for them.  This allows us to point to a location
# on the page, rather than just a page which is what a file link would
# accomplish
sub createRedirects {
    my ($rootdir, $mapfile) = @_;
    open( MAPFD, "<$rootdir/$mapfile" ) || die "Cannot open map file $mapfile\n";
    while (<MAPFD>) {
	my @fields = split(/\+/);
	my $name = $fields[1];
	my $url  = $fields[8];
	if ($url =~ /(.*)\/([^\/]*)\.([HTMLhtml]*)#(.*)/) {
	    my $rooturl  = $1;
	    my $basefile = $2;
	    my $ext      = $3;
	    my $anchor   = $4;
	    if ($basefile ne $anchor) {
		open(RFD, ">$rootdir/$anchor.htm") || die "Cannot open redirect file $anchor.htm\n";
		print RFD "<html><head><meta http-equiv=\"refresh\" content=\"0; url=$basefile.$ext#$anchor\" /></head></html>\n";
		close RFD;
	    }
	}
	else {
	    print STDERR "Could not decode $url\n";
	}

    }
    close MAPFD;
}

# Take all .htm and .html files and add them to the OUTFD file.
# This works in two steps:
# 1. Read and sort the contents of the directory into the array
# @HTMLFiles
# 2. Use the routine MakeHTMLTable to create a table with a given
# number of columns, adding the links within the columns
# Look in $1/$2 for files, but make links relative to $2
sub AddDirectoryContents {
    my $rootdir = $_[0];
    my $dirname = $_[1];

    # 1 Read the files
    my @HTMLFiles = ();
    opendir DIR, "$rootdir/$dirname";

    my $prefixname;
    if ($dirname eq ".") {
	$prefixname = "";
    }
    else {
	$prefixname = "$dirname/";
    }
    while (my $filename = readdir DIR) {
	if ($filename =~ /index\.html?/) { next; }
	if ($filename =~ /.*\.html?$/) {
	    $HTMLFiles[$#HTMLFiles+1] = "$prefixname$filename";
	}
    }
    closedir DIR;

    @HTMLFiles = sort( @HTMLFiles );

    # Format the table
    &MakeHTMLTable(\@HTMLFiles);
}
# MakeHTMLTable takes an array of items and turns them into a table with
# $TableCols columns.
#
sub MakeHTMLTable {
    my ($HTMLFiles) = @_;
    my $nvals = @$HTMLFiles;

    my $nrows = int ( ($nvals + $TableCols - 1) / $TableCols );
    print OUTFD "<TABLE>$eol";
    for (my $j=0; $j<$nrows; $j++) {
	print OUTFD "<TR>";
	for (my $e=0; $e<$TableCols; $e++) {
	    my $filename = $HTMLFiles->[$j + $e * $nrows];
	    my $linkname = $filename;
	    $linkname =~ s/\.html?//;
	    $linkname =~ s/.*\///;
            my $line;
	    if ($filename ne "") {
		$line = "<A HREF=\"$filename\">$linkname</A>";
	    }
	    else {
		$line = "";
	    }
	    print OUTFD "<TD>$line</TD>$eol";
	}
	print OUTFD "</TR>$eol";
    }
    print OUTFD "</TABLE>$eol";
}
